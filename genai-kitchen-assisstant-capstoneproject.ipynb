{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[],"dockerImageVersionId":31012,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"üç≥ Gen AI Kitchen Companion: Smart Recipes from What You Have\nThis project enhances home cooking by integrating GenAI to generate smart recipe suggestions based on ingredients users already have at home.\n\nüîß Capabilities Used:\nFew-shot Prompting: Generate complete recipes from simple lists of ingredients.\n\nStructured Output: Return recipe name, ingredients used, and step-by-step cooking instructions in JSON format.\n\nLightweight Interaction: No database needed‚Äîjust smart prompt engineering and Google Gemini API for personalized assistance.\n","metadata":{}},{"cell_type":"markdown","source":"## üß† Problem Statement\n\nMost recipe apps fail when you don‚Äôt have all the ingredients. Users need something smarter ‚Äî a system that takes what‚Äôs in their pantry or fridge, understands their dietary preferences, and gives them easy-to-follow, personalized instructions.\n\nThe Gen AI Kitchen Companion solves this with intelligent prompting and structured generation techniques.\n","metadata":{}},{"cell_type":"markdown","source":"## üîß Gen AI Capabilities Used\n\n| Capability | Description |\n|------------|-------------|\n| **Structured Output** | Recipe output is structured as JSON: ingredients, steps, time, etc. |\n| **Few-shot Prompting** | Prompt tuned with examples for high-quality recipe results |\n| **Function Calling (optional)** | Used to expand the recipe or fetch a shopping list if ingredients are missing |\n","metadata":{}},{"cell_type":"code","source":"import os\nfrom google import genai\nimport numpy as np\nfrom kaggle_secrets import UserSecretsClient\nfrom sklearn.metrics.pairwise import cosine_similarity\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-09T10:54:25.759973Z","iopub.execute_input":"2025-07-09T10:54:25.760854Z","iopub.status.idle":"2025-07-09T10:54:27.952128Z","shell.execute_reply.started":"2025-07-09T10:54:25.760824Z","shell.execute_reply":"2025-07-09T10:54:27.951073Z"}},"outputs":[{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/pydantic/_internal/_generate_schema.py:623: UserWarning: <built-in function any> is not a Python type (it may be an instance of an object), Pydantic will allow any object with no validation since we cannot even enforce that the input is an instance of the given type. To get rid of this error wrap the type with `pydantic.SkipValidation`.\n  warn(\n","output_type":"stream"}],"execution_count":1},{"cell_type":"markdown","source":"## üîê API Key Management and Environment Setup\n\nTo integrate Google services such as Vertex AI or embedding models via API, it‚Äôs important to handle credentials securely, especially in public or collaborative environments like Kaggle. Here's how we manage API keys using Kaggle Secrets:\n\n### ‚úÖ Securely Fetching Google API Key from Kaggle Secrets","metadata":{}},{"cell_type":"code","source":"# ‚úÖ Get API key from Kaggle secrets\nGOOGLE_API_KEY = UserSecretsClient().get_secret(\"Google_API_Key\")\n\n# Set the Google API key in the environment variable\nos.environ[\"GOOGLE_API_KEY\"] = GOOGLE_API_KEY","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-09T10:54:42.351864Z","iopub.execute_input":"2025-07-09T10:54:42.352348Z","iopub.status.idle":"2025-07-09T10:54:42.637314Z","shell.execute_reply.started":"2025-07-09T10:54:42.352321Z","shell.execute_reply":"2025-07-09T10:54:42.636147Z"}},"outputs":[],"execution_count":2},{"cell_type":"markdown","source":"### üß† Generating Smart Recipes Using Few-Shot Prompting\n\nThis function uses **few-shot prompting** to guide the Gemini model in generating creative recipe suggestions based on the user's available ingredients.\n\nIt provides several example ingredient lists and corresponding recipe responses to help the model understand the desired format and style. The model then generates a relevant recipe for the user's current input using the Gemini 2.0 Flash model.\n","metadata":{}},{"cell_type":"code","source":"def get_smart_recipe(ingredients_list):\n    # Convert list to readable string\n    user_ingredients = \", \".join(ingredients_list)\n\n    # Few-shot examples to guide the model\n    prompt = f\"\"\"Suggest a recipe using available ingredients.\n\nUser: tomato, onion, garlic, turmeric\nAssistant: Try making a simple tomato curry. Saut√© chopped onion and garlic in oil, add chopped tomatoes and turmeric. Cook until soft and serve with rice.\n\nUser: paneer, bell pepper, onion, cumin\nAssistant: You can make Paneer Tikka Masala. Saut√© onions and cumin seeds, add bell peppers and paneer. Add masala and cook until tender.\n\nUser: rice, coconut, green chili, mustard seeds\nAssistant: Make coconut rice! Cook rice, then fry mustard seeds and green chilies in oil. Mix in grated coconut and add to the rice.\n\nUser: {user_ingredients}\nAssistant:\"\"\"\n\n    # Load Gemini Pro model\n    import google.generativeai as genai\n    genai.configure(api_key=os.environ[\"GOOGLE_API_KEY\"])\n\n    model = genai.GenerativeModel(\"gemini-2.0-flash\")\n    response = model.generate_content(prompt)\n\n    return response.text.strip()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-09T10:54:48.980516Z","iopub.execute_input":"2025-07-09T10:54:48.981391Z","iopub.status.idle":"2025-07-09T10:54:48.987479Z","shell.execute_reply.started":"2025-07-09T10:54:48.981360Z","shell.execute_reply":"2025-07-09T10:54:48.986591Z"}},"outputs":[],"execution_count":3},{"cell_type":"markdown","source":"### üîç Generating Recipe Embeddings for Similarity Matching\n\nThis function creates vector embeddings for ingredient lists or dish descriptions using the **Gemini 2.0 Flash model**.\n\nThese embeddings are useful for comparing recipes using **cosine similarity**, enabling the system to recommend recipes similar to the user's input. The function also includes error handling and debug logs to ensure robustness.\n","metadata":{}},{"cell_type":"code","source":"def get_recipe_embedding(text):\n    import google.generativeai as genai\n    genai.configure(api_key=os.environ[\"GOOGLE_API_KEY\"])\n    \n    try:\n        # Get the embedding for the ingredient list or dish description\n        embedding_prompt = f\"Generate a vector representation for the ingredients or dish: {text}\"\n        model = genai.GenerativeModel(\"gemini-2.0-flash\")\n        embedding_response = model.generate_content(embedding_prompt)\n\n        print(\"Embedding Response:\", embedding_response.text.strip())  # Debugging line\n\n        embedding_str = embedding_response.text.strip()\n        if not embedding_str:\n            print(\"‚ö†Ô∏è Warning: Embedding is empty.\")\n            return np.zeros(0)\n        \n        # Convert string to numpy array\n        embedding = np.fromiter(map(float, embedding_str.split(',')), dtype=float)\n        if embedding.size == 0:\n            print(\"‚ö†Ô∏è Warning: Embedding array is empty.\")\n        return embedding\n\n    except Exception as e:\n        print(f\"‚ùå Error generating embedding: {e}\")\n        return np.zeros(0)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-09T10:54:52.999931Z","iopub.execute_input":"2025-07-09T10:54:53.000290Z","iopub.status.idle":"2025-07-09T10:54:53.008074Z","shell.execute_reply.started":"2025-07-09T10:54:53.000258Z","shell.execute_reply":"2025-07-09T10:54:53.007086Z"}},"outputs":[],"execution_count":4},{"cell_type":"markdown","source":"### üß† Structured Recipe Generation with JSON Output\n\nThis function uses a prompt-based approach to generate a **structured recipe** from the user's input (such as ingredients or dish request). It leverages the **Gemini 2.0 Flash** model to return a JSON object with:\n\n- `recipe_name`: Short name of the suggested dish  \n- `ingredients`: List of required ingredients  \n- `steps`: Step-by-step cooking instructions  \n- `cuisine`: Suggested cuisine (e.g., Indian, Italian)  \n- `meal_type`: Appropriate meal time (e.g., lunch, snack)  \n- `prep_time`: Estimated preparation time in minutes  \n\nThe output is parsed from the model response into a valid JSON format for further use.\n","metadata":{}},{"cell_type":"code","source":"def get_structured_recipe(user_input):\n    structured_prompt = f\"\"\"\nYou are a smart kitchen assistant. Based on the user's available ingredients or recipe request, return a recipe in structured JSON format with the following keys:\n\n- recipe_name: short dish name\n- ingredients: list of required ingredients\n- steps: list of cooking instructions\n- cuisine: suitable cuisine (e.g., Indian, Italian)\n- meal_type: breakfast, lunch, dinner, snack, etc.\n- prep_time: estimated preparation time in minutes\n\nRespond **only** with valid JSON.\n\nUser input: \"{user_input}\"\nJSON:\n\"\"\"\n    \n    import google.generativeai as genai\n    import os\n    import json\n\n    genai.configure(api_key=os.environ[\"GOOGLE_API_KEY\"])\n    model = genai.GenerativeModel(\"gemini-2.0-flash\")\n\n    try:\n        response = model.generate_content(structured_prompt)\n        return json.loads(response.text)\n    except json.JSONDecodeError:\n        return {\"error\": \"‚ö†Ô∏è Failed to parse structured recipe response.\"}","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-09T10:54:56.304949Z","iopub.execute_input":"2025-07-09T10:54:56.305271Z","iopub.status.idle":"2025-07-09T10:54:56.312277Z","shell.execute_reply.started":"2025-07-09T10:54:56.305247Z","shell.execute_reply":"2025-07-09T10:54:56.310788Z"}},"outputs":[],"execution_count":5},{"cell_type":"markdown","source":"## üîç Recipe Retrieval Using Embeddings\n\nTo intelligently match user-provided ingredients or phrases to the most relevant recipe, we compute **cosine similarity** between the user's input and a database of recipe embeddings.\n\n### üß† `find_similar_recipe()` Function","metadata":{}},{"cell_type":"code","source":"def find_similar_recipe(user_input, recipe_db):\n    user_embedding = get_recipe_embedding(user_input)\n    \n    # Check if the embedding is valid\n    if user_embedding.size == 0:\n        print(\"Error: No valid embedding found for the user input.\")\n        return \"Sorry, I couldn't find a matching recipe.\"\n\n    recipe_embeddings = [recipe['embedding'] for recipe in recipe_db]\n    \n    # Calculate cosine similarity\n    similarities = cosine_similarity([user_embedding], recipe_embeddings)\n    most_similar_index = np.argmax(similarities)\n    return recipe_db[most_similar_index]['recipe']\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-09T10:55:00.700399Z","iopub.execute_input":"2025-07-09T10:55:00.700816Z","iopub.status.idle":"2025-07-09T10:55:00.706920Z","shell.execute_reply.started":"2025-07-09T10:55:00.700789Z","shell.execute_reply":"2025-07-09T10:55:00.705802Z"}},"outputs":[],"execution_count":6},{"cell_type":"markdown","source":"## üß™ Main Script: Gen AI Kitchen Companion Demo\n\nThis is the interactive script for testing your Gen AI Kitchen Companion using multiple strategies:\n- üîç **Embeddings + Vector Search**\n- ü§ñ **Few-shot Prompting**\n- üì¶ **Structured JSON Output**\n\n### üöÄ Script","metadata":{}},{"cell_type":"code","source":"if __name__ == \"__main__\":\n    # Example recipe database with pre-calculated embeddings\n    recipe_db = [\n        {'recipe': 'Tomato Rice', 'embedding': get_recipe_embedding('tomato, rice, cumin, turmeric')},\n        {'recipe': 'Paneer Bhurji', 'embedding': get_recipe_embedding('paneer, onion, tomato, spices')},\n        {'recipe': 'Lemon Rice', 'embedding': get_recipe_embedding('lemon, rice, mustard seeds, curry leaves')},\n        {'recipe': 'Mixed Vegetable Pulao', 'embedding': get_recipe_embedding('carrot, beans, peas, rice, garam masala')},\n        {'recipe': 'Simple Khichdi', 'embedding': get_recipe_embedding('rice, moong dal, turmeric, salt')}\n    ]\n\n    while True:\n        user_input = input(\"\\nüßë‚Äçüç≥ What ingredients do you have? (or type 'exit'): \")\n        if user_input.lower() == \"exit\":\n            break\n\n        # ‚úÖ Few-shot Prompting\n        basic_response = get_smart_recipe(user_input)\n        print(\"\\nüë©‚Äçüç≥ Assistant (Few-shot Recipe Suggestion):\", basic_response)\n\n        # ‚úÖ Embeddings + Vector Search\n        similar_recipe = find_similar_recipe(user_input, recipe_db)\n        print(\"üç≤ Assistant (Similar Recipe Suggestion):\", similar_recipe)\n\n        # ‚úÖ Structured Output / JSON Mode\n        structured_json = get_structured_recipe(user_input)\n        print(\"üì¶ Assistant (Structured Recipe Info in JSON):\")\n        print(structured_json)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-09T10:55:05.985129Z","iopub.execute_input":"2025-07-09T10:55:05.985437Z"}},"outputs":[{"name":"stdout","text":"Embedding Response: Here's a possible vector representation for the ingredients: tomato, rice, cumin, turmeric. This representation is based on a simple attribute-based approach.  You can think of it as a simplified feature vector.\n\n**Conceptual Basis:**\n\nWe'll represent each ingredient based on these categories:\n\n*   **Flavor Profile:** (Sweet, Savory, Spicy, Earthy, Bitter)\n*   **Culinary Use:** (Base, Spice, Side, Garnish)\n*   **Color:** (Red, White/Light, Yellow/Orange, Brown/Dark)\n*   **Texture:** (Soft, Firm, Grainy, Powdery)\n*   **Region of Origin:** (Mediterranean, Asian, South Asian, Latin American)\n\n**Vector Representation:**\n\nWe'll use a 1/0 (or a scaled value) to indicate the presence or absence of a characteristic.\n\n```\nIngredient Vector: [Flavor Profile, Culinary Use, Color, Texture, Region of Origin]\n```\n\n**Specific Vectors:**\n\n*   **Tomato:** `[Sweet(0.7), Savory(0.5), Spicy(0.1), Earthy(0.2), Bitter(0.1), Base(0.8), Spice(0.2), Side(0.3), Garnish(0.5), Red(0.9), White/Light(0.1), Yellow/Orange(0.3), Brown/Dark(0.1), Soft(0.9), Firm(0.3), Grainy(0.1), Powdery(0.0), Mediterranean(0.6), Asian(0.1), South Asian(0.1), Latin American(0.8)]`\n\n*   **Rice:** `[Sweet(0.2), Savory(0.6), Spicy(0.0), Earthy(0.3), Bitter(0.0), Base(0.9), Spice(0.0), Side(0.9), Garnish(0.1), Red(0.0), White/Light(0.9), Yellow/Orange(0.2), Brown/Dark(0.3), Soft(0.4), Firm(0.5), Grainy(0.9), Powdery(0.0), Asian(0.7), Mediterranean(0.3), South Asian(0.7), Latin American(0.4)]`\n\n*   **Cumin:** `[Sweet(0.1), Savory(0.8), Spicy(0.6), Earthy(0.9), Bitter(0.3), Base(0.0), Spice(0.9), Side(0.0), Garnish(0.3), Red(0.0), White/Light(0.0), Yellow/Orange(0.0), Brown/Dark(0.8), Soft(0.0), Firm(0.0), Grainy(0.7), Powdery(0.7), Mediterranean(0.6), Asian(0.1), South Asian(0.7), Latin American(0.5)]`\n\n*   **Turmeric:** `[Sweet(0.1), Savory(0.5), Spicy(0.8), Earthy(0.9), Bitter(0.2), Base(0.0), Spice(0.9), Side(0.0), Garnish(0.3), Red(0.0), White/Light(0.0), Yellow/Orange(0.9), Brown/Dark(0.3), Soft(0.0), Firm(0.0), Grainy(0.7), Powdery(0.8), Asian(0.2), Mediterranean(0.0), South Asian(0.9), Latin American(0.1)]`\n\n**Explanation of Values:**\n\n*   The numbers represent the degree to which the ingredient possesses that attribute, ranging from 0.0 (not at all) to 1.0 (very strongly).  These are subjective estimates.\n*   I've tried to reflect common perceptions. For example, tomatoes are considered both sweet and savory, used as a base ingredient and garnish, and have both red and yellow varieties. Turmeric is very strongly associated with its yellow/orange color and South Asian cuisine.\n\n**Improvements and Alternatives:**\n\n*   **Larger Feature Set:**  A more comprehensive feature set could include nutritional information (e.g., vitamin C content), chemical compounds (e.g., lycopene), and more specific flavor descriptors.\n*   **Word Embeddings:**  You could use pre-trained word embeddings (like Word2Vec, GloVe, or FastText) trained on a large corpus of text related to food and recipes. This would capture semantic relationships between the ingredients based on how they are used in text.  You would then average the vectors for the ingredients in a dish to create a dish vector.\n*   **Knowledge Graph Embeddings:** If you have access to a food knowledge graph (linking ingredients, dishes, and properties), you could use knowledge graph embedding techniques (e.g., TransE, ComplEx) to learn vector representations.\n*   **Learned Embeddings from Recipe Data:**  Train a neural network (e.g., a sequence-to-sequence model or a transformer) on a large dataset of recipes. The network could learn to predict the ingredients of a dish or the next ingredient in a recipe.  The hidden layer activations could then be used as vector representations.\n*   **Consider Context:** The ideal vector representation often depends on the downstream task. Are you trying to find similar dishes, suggest ingredient substitutions, or predict flavor pairings? The choice of features and representation method should be tailored to the specific goal.\n\nThis provides a basic foundation.  The best approach depends on the complexity required and the available data. Remember to normalize the vectors if you plan to calculate distances or similarities between them.\n‚ùå Error generating embedding: could not convert string to float: \"Here's a possible vector representation for the ingredients: tomato\"\nEmbedding Response: Here's a vector representation concept for the ingredients: paneer, onion, tomato, spices, along with explanations and different approaches.\n\n**Conceptual Approach**\n\nThe goal is to represent each ingredient or dish as a vector in a multi-dimensional space where each dimension corresponds to a specific attribute or feature.  Attributes are characteristics of the ingredients or dish.  Similar ingredients or dishes will have vectors that are closer to each other in this space.\n\n**Possible Dimensions (Attributes)**\n\nHere are some potential dimensions to consider for your vector space:\n\n*   **Taste Profile:**\n    *   `Sweetness` (0-1)\n    *   `Sourness` (0-1)\n    *   `Saltiness` (0-1)\n    *   `Bitterness` (0-1)\n    *   `Umami` (0-1)\n    *   `Spice Level` (0-1) - (Heat)\n\n*   **Texture:**\n    *   `Creaminess` (0-1)\n    *   `Crunchiness` (0-1)\n    *   `Softness` (0-1)\n    *   `Firmness` (0-1)\n    *   `Juiciness` (0-1)\n\n*   **Aroma:**\n    *   `Fruity` (0-1)\n    *   `Earthy` (0-1)\n    *   `Floral` (0-1)\n    *   `Spicy` (0-1)\n    *   `Savory` (0-1)\n    *   `Pungent` (0-1)\n\n*   **Origin/Cuisine:**\n    *   `Indian` (0-1)\n    *   `Italian` (0-1)\n    *   `Mexican` (0-1)\n    *   `Asian` (0-1)\n    *   `Western` (0-1)\n\n*   **Color:**  (This could be represented as separate R, G, B values or general color categories)\n    *   `Red` (0-1)\n    *   `Green` (0-1)\n    *   `White` (0-1)\n    *   `Yellow` (0-1)\n    *   `Orange` (0-1)\n\n*   **Nutritional Value (Simplified):**\n    *   `Protein` (0-1)\n    *   `Fat` (0-1)\n    *   `Carbohydrates` (0-1)\n\n**Example Vector Representations (Illustrative)**\n\nBased on these dimensions, here's how you *might* represent the ingredients.  Remember, these are just examples, and the specific values will depend on the level of detail you want and how you define the scales.\n\n```python\nimport numpy as np\n\npaneer = np.array([\n    0.0, 0.0, 0.1, 0.0, 0.0, 0.0,  # Taste\n    0.9, 0.0, 0.9, 0.8, 0.0,  # Texture\n    0.0, 0.0, 0.0, 0.0, 0.1, 0.0,  # Aroma\n    0.9, 0.0, 0.0, 0.0, 0.0,  # Origin\n    1.0, 0.0, 0.0, 0.0, 0.0, # Color\n    0.8, 0.6, 0.1  # Nutritional Value\n])\n\nonion = np.array([\n    0.1, 0.1, 0.3, 0.1, 0.2, 0.0,  # Taste\n    0.1, 0.9, 0.2, 0.2, 0.7,  # Texture\n    0.0, 0.7, 0.0, 0.2, 0.8, 0.9,  # Aroma\n    0.0, 0.0, 0.0, 0.0, 0.0,  # Origin -  Could be argued for some origin value\n    1.0, 0.0, 1.0, 0.0, 0.0, # Color\n    0.1, 0.0, 0.1  # Nutritional Value\n])\n\ntomato = np.array([\n    0.2, 0.8, 0.2, 0.0, 0.7, 0.0,  # Taste\n    0.1, 0.2, 0.3, 0.4, 0.9,  # Texture\n    0.7, 0.1, 0.0, 0.0, 0.5, 0.0,  # Aroma\n    0.0, 0.0, 0.0, 0.0, 0.0,  # Origin - Could be argued for some origin value\n    1.0, 0.0, 0.0, 0.0, 0.0, # Color\n    0.1, 0.0, 0.1  # Nutritional Value\n])\n\nspices = np.array([\n    0.1, 0.0, 0.2, 0.5, 0.1, 0.9,  # Taste\n    0.0, 0.8, 0.0, 0.0, 0.0,  # Texture\n    0.0, 0.8, 0.9, 0.9, 0.9, 0.9,  # Aroma\n    0.9, 0.0, 0.0, 0.0, 0.0,  # Origin\n    0.0, 0.0, 0.0, 1.0, 0.0, # Color\n    0.1, 0.1, 0.1  # Nutritional Value\n])\n\nprint(\"Paneer:\", paneer)\nprint(\"Onion:\", onion)\nprint(\"Tomato:\", tomato)\nprint(\"Spices:\", spices)\n```\n\n**Explanation of Values (Examples)**\n\n*   **Paneer:**  High on creaminess and firmness.  High on protein, relatively high on fat. Indian origin. White Color.\n*   **Onion:**  Some sweetness, sourness, and saltiness.  Crunchy when raw, softens when cooked.  Pungent aroma. White and Green Color.\n*   **Tomato:** High sourness and umami. Juicy. Fruity aroma. Red Color.\n*   **Spices:**  High spice level (heat).  Strong aromas, including earthy, floral, and spicy.  Indian Origin, Yellow color.\n\n**Important Considerations:**\n\n1.  **Normalization:** It's crucial to normalize your values (scale them to a range like 0-1) to prevent dimensions with larger absolute values from dominating the distance calculations.\n\n2.  **Subjectivity:**  The assignment of values is inherently subjective.  Different people may have different perceptions of taste, texture, and aroma.\n\n3.  **Complexity:**  You can add more dimensions to represent ingredients more precisely.  However, too many dimensions can lead to the \"curse of dimensionality,\" where distances become less meaningful.\n\n4.  **Distance Metrics:**  Once you have your vectors, you can use distance metrics (e.g., Euclidean distance, cosine similarity) to measure the similarity between ingredients.\n\n**Using the Vectors**\n\nWith these vectors, you can:\n\n*   **Find Similar Ingredients:** Calculate the distances between vectors to find ingredients that are similar in terms of taste, texture, aroma, etc.\n*   **Suggest Substitutions:** If an ingredient is unavailable, suggest similar ingredients based on vector proximity.\n*   **Analyze Recipes:**  Represent a recipe as a weighted average of its ingredient vectors. This can help you understand the overall characteristics of the dish.\n\n**Alternative Approach: Word Embeddings (More Advanced)**\n\nFor a more sophisticated approach, you could use word embeddings (like Word2Vec or GloVe).  This would involve training a model on a large corpus of text related to food and recipes.  The model would learn vector representations for the words (ingredients) based on their context.\n\nFor example, you could train a model on a corpus of recipes, food blogs, and restaurant reviews.  The model would learn that \"paneer\" is often associated with words like \"curry,\" \"Indian,\" \"creamy,\" and \"spicy.\"  As a result, the vector for \"paneer\" would be close to the vectors for these related words.  This approach requires more data and computational resources but can capture more subtle semantic relationships.\n\nIn summary, the best approach depends on the complexity you need and the resources you have available.  The conceptual approach with manually assigned values is a good starting point.  If you need more nuanced representations, consider using word embeddings.\n‚ùå Error generating embedding: could not convert string to float: \"Here's a vector representation concept for the ingredients: paneer\"\nEmbedding Response: Okay, here are a few ways to represent those ingredients as a vector, with explanations of the logic behind each:\n\n**1.  One-Hot Encoding (Simple, Ingredient-Focused)**\n\n   *   **Concept:**  Each ingredient gets its own dimension in the vector.  The dimension is 1 if the ingredient is present, 0 otherwise.\n\n   *   **Vector:** `[1, 1, 1, 1]`  (Assuming the order is lemon, rice, mustard seeds, curry leaves)\n\n   *   **Explanation:**\n        *   Index 0:  Lemon (1 = Present)\n        *   Index 1:  Rice (1 = Present)\n        *   Index 2:  Mustard Seeds (1 = Present)\n        *   Index 3:  Curry Leaves (1 = Present)\n\n   *   **Pros:**  Easy to understand and implement.  Directly represents the presence/absence of specific ingredients.\n   *   **Cons:** Doesn't capture any relationships between ingredients or their quantities.  Not scalable for a large vocabulary of ingredients.  Loses information about amounts.\n\n**2. TF-IDF based on Recipes (Recipe-Focused)**\n\n   *   **Concept:** This approach leverages a larger corpus of recipes.  We treat each recipe as a document and apply TF-IDF (Term Frequency-Inverse Document Frequency) to determine the importance of each ingredient within the context of the recipe.\n\n   *   **Steps (Illustrative):**\n\n     1.  **Recipe Corpus:**  You'd need a database of recipes. Let's imagine a simplified example:\n\n           *   Recipe 1: Lemon Rice (lemon, rice, mustard seeds, curry leaves, oil, salt)\n           *   Recipe 2:  Mustard Greens Curry (mustard greens, mustard seeds, chili, turmeric)\n           *   Recipe 3:  Lemonade (lemon, water, sugar)\n           *   Recipe 4:  Plain Rice (rice, water, salt)\n           *   Recipe 5:  Curry Leaf Chutney (curry leaves, coconut, chili, salt)\n\n     2.  **Term Frequency (TF):** For the \"Lemon Rice\" recipe (our target):\n\n           *   TF(lemon) = 1/6\n           *   TF(rice) = 1/6\n           *   TF(mustard seeds) = 1/6\n           *   TF(curry leaves) = 1/6\n\n     3.  **Inverse Document Frequency (IDF):**  This measures how rare an ingredient is across the entire recipe corpus.\n\n           *   IDF(lemon) = log(5/2)  (Lemon appears in 2 out of 5 recipes)\n           *   IDF(rice) = log(5/2) (Rice appears in 2 out of 5 recipes)\n           *   IDF(mustard seeds) = log(5/2) (Mustard seeds appear in 2 out of 5 recipes)\n           *   IDF(curry leaves) = log(5/2) (Curry leaves appear in 2 out of 5 recipes)\n\n     4.  **TF-IDF:**  Multiply TF * IDF for each ingredient.\n\n           *   TF-IDF(lemon) = (1/6) * log(5/2)  ‚âà 0.15\n           *   TF-IDF(rice) = (1/6) * log(5/2) ‚âà 0.15\n           *   TF-IDF(mustard seeds) = (1/6) * log(5/2) ‚âà 0.15\n           *   TF-IDF(curry leaves) = (1/6) * log(5/2) ‚âà 0.15\n\n     5.  **Vector Representation:**  The vector is now:\n\n           *   `[0.15, 0.15, 0.15, 0.15]`\n\n   *   **Pros:**  Captures the relative importance of ingredients *within* a specific dish/recipe. Accounts for rarity.  Scalable (you can add more recipes and ingredients).\n   *   **Cons:** Requires a large, relevant recipe corpus.  The vector is specific to the recipe used to generate it.  Doesn't capture semantic relationships beyond recipe co-occurrence.\n\n**3.  Ingredient Properties/Attributes (More Semantic)**\n\n   *   **Concept:** Define a set of relevant properties or attributes for each ingredient.  The vector represents the values of these attributes.\n\n   *   **Example Attributes:**\n      *   Flavor Profile (Sour, Savory, Spicy, Sweet, Bitter)\n      *   Texture (Soft, Firm, Crispy, Liquid, Grainy)\n      *   Cuisine (Indian, Asian, Mediterranean, Western)\n      *   Use Case (Main Course, Side Dish, Garnish, Sauce)\n\n   *   **Vector (Illustrative):**\n\n      *   **Lemon:**  `[1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1]` (Sour, Firm, Mediterranean, Garnish)\n      *   **Rice:**   `[0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1]` (Savory, Grainy, Asian, Side Dish)\n      *   **Mustard Seeds:** `[0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0]` (Savory, Spicy, Bitter, Indian)\n      *   **Curry Leaves:** `[0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1]` (Savory, Spicy, Bitter, Indian, Garnish)\n\n      * Combined (Sum): `[1, 4, 3, 0, 2, 0, 4, 0, 0, 0, 0, 1, 0, 3]`\n\n   *   **Explanation:**\n        *   Each section represents a group of properties (e.g., first 5 indices for Flavor Profile).\n        *   Within each section, a 1 indicates that the ingredient possesses that property.\n\n   *   **Pros:**  Captures semantic meaning and relationships between ingredients based on their characteristics. More flexible than one-hot encoding.\n   *   **Cons:** Requires careful definition of attributes.  Subjective assignment of values.  Can be high-dimensional.\n\n**4. Word Embeddings (Advanced, Requires Training Data)**\n\n*   **Concept:**  Use pre-trained word embeddings (like Word2Vec, GloVe, or FastText) to represent each ingredient.  These embeddings are trained on massive text corpora and capture semantic relationships between words (in this case, ingredients).\n*   **Steps:**\n    1.  **Choose a Pre-trained Model:** Download a pre-trained word embedding model (e.g., a GloVe model trained on Wikipedia).\n    2.  **Get Embeddings:** Look up the vector representation for each ingredient in the model's vocabulary.  For example:\n        *   `vector_lemon = model['lemon']`\n        *   `vector_rice = model['rice']`\n        *   `vector_mustard_seeds = model['mustard_seeds']` (You might need to combine \"mustard\" and \"seeds\" or use a similar term if \"mustard_seeds\" isn't in the vocabulary).\n        *   `vector_curry_leaves = model['curry_leaves']` (Same as above).\n    3.  **Combine (Optional):** You can combine the individual ingredient vectors (e.g., by averaging or summing) to get a single vector representing the dish.\n\n*   **Pros:** Captures complex semantic relationships.  Leverages knowledge learned from a large text corpus.\n*   **Cons:** Requires access to a pre-trained model.  The quality of the embeddings depends on the training data.  You might need to adapt or fine-tune the embeddings for the specific domain of food/recipes. Can be high dimensional. You must address out-of-vocabulary terms by combining terms or substituting with synonyms.\n\n**Which Approach to Choose?**\n\n*   **For simple presence/absence:** One-hot encoding.\n*   **For relative importance within a recipe, given a dataset of recipes:** TF-IDF.\n*   **For capturing semantic relationships based on ingredient properties:** Attribute-based vectors.\n*   **For the most sophisticated and nuanced semantic relationships (with a need for a pre-trained model):** Word Embeddings.\n\nThe best approach depends entirely on your specific use case and the data you have available. Remember to normalize or scale your vectors appropriately before using them in any machine learning model.\n‚ùå Error generating embedding: could not convert string to float: 'Okay'\nEmbedding Response: Here's a possible vector representation, considering factors like taste profile, texture, cooking method, and origin. Note that this is a simplified representation, and a more sophisticated model would require a larger number of dimensions and a more complex training process.\n\n**Dimensions:**\n\n*   **Sweetness (SW):** 0-1 (0 = Not Sweet, 1 = Very Sweet)\n*   **Savory (SV):** 0-1 (0 = Not Savory, 1 = Very Savory)\n*   **Spicy (SP):** 0-1 (0 = Not Spicy, 1 = Very Spicy)\n*   **Earthy (EA):** 0-1 (0 = Not Earthy, 1 = Very Earthy)\n*   **Creamy (CR):** 0-1 (0 = Not Creamy, 1 = Very Creamy)\n*   **Crunchy (CU):** 0-1 (0 = Not Crunchy, 1 = Very Crunchy)\n*   **Starchy (ST):** 0-1 (0 = Not Starchy, 1 = Very Starchy)\n*   **Legume (LG):** 0-1 (0 = Not a Legume, 1 = Is a Legume)\n*   **Indian Cuisine (IC):** 0-1 (0 = Not commonly in Indian cuisine, 1 = Commonly in Indian cuisine)\n*   **Vegetable (VG):** 0-1 (0 = Not a vegetable, 1 = Is a vegetable)\n\n**Vector Representations:**\n\n*   **Carrot:** `[SW: 0.7, SV: 0.3, SP: 0.1, EA: 0.4, CR: 0.1, CU: 0.6, ST: 0.2, LG: 0.0, IC: 0.2, VG: 1.0]`\n*   **Beans:** `[SW: 0.1, SV: 0.7, SP: 0.1, EA: 0.6, CR: 0.2, CU: 0.2, ST: 0.6, LG: 1.0, IC: 0.3, VG: 1.0]`\n*   **Peas:** `[SW: 0.4, SV: 0.5, SP: 0.1, EA: 0.5, CR: 0.3, CU: 0.3, ST: 0.4, LG: 1.0, IC: 0.3, VG: 1.0]`\n*   **Rice:** `[SW: 0.1, SV: 0.5, SP: 0.0, EA: 0.1, CR: 0.6, CU: 0.0, ST: 0.9, LG: 0.0, IC: 0.7, VG: 0.0]`  (Assuming cooked rice)\n*   **Garam Masala:** `[SW: 0.2, SV: 0.8, SP: 0.8, EA: 0.7, CR: 0.0, CU: 0.0, ST: 0.0, LG: 0.0, IC: 1.0, VG: 0.0]`\n\n**Explanation of Choices:**\n\n*   **Carrot:**  High sweetness, some earthiness, and crunchiness when raw.\n*   **Beans:** High savory and earthy notes, a good source of starch, and clearly a legume.\n*   **Peas:**  A balance of sweetness and savory, with some earthiness.  Also a legume.\n*   **Rice:**  High starch content, often cooked to be creamy, can be quite bland on its own (low sweetness), but absorbs savory flavors well, and is very important in Indian cuisine.\n*   **Garam Masala:**  High savory and spicy elements, a strong earthy base from its blend of spices, and definitively associated with Indian cuisine.  It's not a vegetable or legume.\n\n**How to Use This Representation:**\n\n*   **Similarity/Clustering:** Calculate the distance (e.g., Euclidean distance, cosine similarity) between the vectors to determine how similar two ingredients are.  For instance, you'd expect beans and peas to be relatively close.\n*   **Recipe Recommendation:**  Represent a recipe as the average of the vectors of its ingredients.  Compare this \"recipe vector\" to ingredient vectors to find ingredients that complement the recipe well.\n*   **Ingredient Substitution:** If an ingredient is unavailable, find another ingredient with a similar vector representation.\n*   **Machine Learning:** These vectors can be used as features in machine learning models for tasks like predicting recipe ratings or identifying food pairings.\n\n**Limitations:**\n\n*   **Subjectivity:** Taste is subjective. These values are based on a general understanding of these ingredients.\n*   **Simplification:** A 10-dimensional vector cannot capture all the nuances of flavor and texture.\n*   **Context:** The representation doesn't consider the specific preparation method (e.g., roasted carrots vs. raw carrots).\n\n**Improvements:**\n\n*   **More Dimensions:** Increase the number of dimensions to represent more attributes (e.g., bitterness, acidity, smokiness, geographical origin).\n*   **Data-Driven Training:** Train the vector representations using a large dataset of recipes and ingredient pairings. Word2Vec or similar techniques could be adapted for this purpose.\n*   **Context Awareness:**  Develop a model that considers the context in which an ingredient is used (e.g., the other ingredients in a dish, the cooking method).\n\nThis vector representation provides a starting point for encoding ingredient information in a numerical format. You can adjust the dimensions and values to better suit your specific needs and the granularity of information you want to capture.\n‚ùå Error generating embedding: could not convert string to float: \"Here's a possible vector representation\"\nEmbedding Response: Okay, here's a possible vector representation for the ingredients: rice, moong dal, turmeric, and salt.  Keep in mind that there's no single \"correct\" answer, and the best representation depends on the intended use. This representation focuses on key characteristics that might be relevant in a food context.\n\n**Conceptual Framework:**\n\nWe'll create a vector with the following dimensions (features):\n\n*   **Carbohydrate Content:** (0-1, High to Low)\n*   **Protein Content:** (0-1, High to Low)\n*   **Fat Content:** (0-1, High to Low)\n*   **Fiber Content:** (0-1, High to Low)\n*   **Spice Level:** (0-1, None to Very Spicy)\n*   **Sweetness:** (0-1, Not Sweet to Very Sweet)\n*   **Dominant Flavor Profile:**  We can represent this using three sub-dimensions:\n    *   **Earthy:** (0-1, Not Earthy to Very Earthy)\n    *   **Nutty:** (0-1, Not Nutty to Very Nutty)\n    *   **Savory:** (0-1, Not Savory to Very Savory)\n*   **Color Intensity:** (0-1, Pale to Intense) (Relating to visual impact in cooking)\n*   **Culinary Use - Base:** (0-1, 1 if used as a base, 0 if not)\n*   **Culinary Use - Seasoning:** (0-1, 1 if used as a seasoning, 0 if not)\n\n**Vector Representations:**\n\n*   **Rice:** `[0.9, 0.07, 0.01, 0.02, 0.0, 0.0, 0.2, 0.1, 0.4, 0.05, 1, 0]`\n    *   High in Carbohydrates, Low in Protein, Fat and Fiber.  Not Spicy or Sweet.  Slightly Earthy and Savory. Pale in Color.  Often used as a base.\n*   **Moong Dal (Split Mung Beans):** `[0.6, 0.24, 0.01, 0.15, 0.0, 0.0, 0.3, 0.5, 0.7, 0.2, 0, 0]`\n    *   Medium in Carbohydrates, relatively high in Protein and Fiber.  Not Spicy or Sweet. Earthy, Nutty, and Savory. Light Yellow in Color.\n*   **Turmeric:** `[0.6, 0.1, 0.1, 0.2, 0.4, 0.0, 0.6, 0.0, 0.5, 0.9, 0, 1]`\n    *   Medium in Carbohydrates. Medium in Fiber. Slightly Spicy. Very Earthy. Very Intense Yellow-Orange color. Used as a seasoning.\n*   **Salt:** `[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0, 1]`\n    *   Zero for nutrient values. Purely Savory. Used as a seasoning.\n\n**Explanation and Considerations:**\n\n*   **Normalization:** The values are normalized to be between 0 and 1.\n*   **Subjectivity:**  Some values are subjective estimations based on common knowledge.  A more rigorous approach would involve analyzing nutritional data and flavor profiles.\n*   **Context Dependence:** This representation is designed for a general culinary context.  If you were focusing on, say, Ayurvedic medicine, you might include dimensions related to energetic properties (heating/cooling).\n*   **Dimensionality:** The number of dimensions can be increased to capture more nuanced information.  For example, you could add dimensions for specific vitamins or minerals.\n*   **Alternative Representations:**\n\n    *   **Word Embeddings (Word2Vec, GloVe, FastText):**  You could train a word embedding model on a large corpus of recipes and food-related text. The resulting word vectors would capture semantic relationships between ingredients. This would likely be better if you're trying to predict ingredient substitutions or discover novel recipes.\n    *   **Knowledge Graphs:**  Represent ingredients as nodes in a knowledge graph, with edges representing relationships like \"is a spice,\" \"pairs well with,\" or \"contains.\"\n\n**How to Use This:**\n\n*   **Similarity Calculations:** You can use these vectors to calculate the similarity between ingredients using measures like cosine similarity or Euclidean distance.  This could be useful for suggesting ingredient substitutions.\n*   **Clustering:** You could cluster ingredients based on their vector representations to identify groups of similar ingredients.\n*   **Machine Learning:** You can use these vectors as features in machine learning models for tasks like recipe classification or predicting recipe ratings.\n\nRemember to adapt the dimensions and values to best suit your specific needs and data.  If you can provide more information about the intended use case, I can refine the vector representation further.\n‚ùå Error generating embedding: could not convert string to float: 'Okay'\n","output_type":"stream"},{"output_type":"stream","name":"stdin","text":"\nüßë‚Äçüç≥ What ingredients do you have? (or type 'exit'):  apple,venigar\n"},{"name":"stdout","text":"\nüë©‚Äçüç≥ Assistant (Few-shot Recipe Suggestion): Okay, with the letters \"a, p, p, l, e,  v, e, n, i, g, a, r\", you can make **Apple Vinegar**.\n\nTherefore, I suggest a recipe using **apple cider vinegar**:\n\n**Apple Cider Vinegar Salad Dressing**\n\nThis is a very simple and versatile salad dressing you can make with just a few extra ingredients you likely have on hand.  It highlights the flavor of the apple cider vinegar.\n\n**Ingredients:**\n\n*   3 tablespoons apple cider vinegar\n*   1 tablespoon olive oil (or other oil of your choice)\n*   1 teaspoon honey (or maple syrup, or sugar - adjust to your preference)\n*   Salt and pepper to taste\n\n**Instructions:**\n\n1.  **Combine:** In a small bowl, whisk together the apple cider vinegar, olive oil, and honey until well combined.\n2.  **Season:** Add salt and pepper to taste.\n3.  **Taste and Adjust:** Taste the dressing and adjust the ingredients as needed.  Add more honey if you want it sweeter, or more apple cider vinegar if you want it tangier.\n4.  **Serve:** Drizzle over your favorite salad.\n\n**Notes:**\n\n*   You can add other herbs and spices to this dressing, such as Dijon mustard, garlic powder, dried herbs, or fresh herbs like parsley or chives.\n*   This dressing can be stored in an airtight container in the refrigerator for up to a week.\n*   Shake well before using.\n\nEnjoy!  This simple dressing can be used on a variety of salads, from simple green salads to more elaborate salads with fruits, nuts, and cheeses.\nEmbedding Response: Okay, let's create a vector representation for \"apple, vinegar\".  This is a bit tricky because vector representations are usually associated with pre-trained models that have seen a lot of text data.  However, we can use a simplified, hand-crafted approach to illustrate the concept.\n\nHere's one way to represent the ingredients as a vector, focusing on potential dimensions related to flavor, use, and origin:\n\n**Dimensions (Features):**\n\n1.  **Sweetness:** (0-1, 1 being very sweet)\n2.  **Acidity:** (0-1, 1 being very acidic)\n3.  **Fruitiness:** (0-1, 1 being very fruity)\n4.  **Savoryness:** (0-1, 1 being very savory)\n5.  **Fermented:** (0-1, 1 being fermented)\n6.  **Cooking Use:** (0-1, Proportion of use in cooking)\n7.  **Salad Use:** (0-1, Proportion of use in salads)\n8.  **Preservation:** (0-1, Proportion of use in preservation)\n9.  **Sauce Use:** (0-1, Proportion of use in sauces)\n10. **Western Cuisine Association:** (0-1, 1 being strongly associated)\n11. **Eastern Cuisine Association:** (0-1, 1 being strongly associated)\n12. **Commonality:** (0-1, 1 being highly common ingredient)\n**Vector Representations:**\n\n*   **Apple:**\n\n    `[0.8, 0.2, 0.9, 0.1, 0.0, 0.7, 0.6, 0.2, 0.1, 0.9, 0.4, 1.0]`\n\n    *   High sweetness, moderate acidity, very fruity.\n    *   Low savoryness, not fermented.\n    *   Used in cooking and salads significantly, some use in preservation and sauces.\n    *   Strong association with Western cuisine, moderate with Eastern.\n    *   Highly common.\n\n*   **Vinegar:**\n\n    `[0.1, 0.9, 0.2, 0.1, 1.0, 0.3, 0.7, 0.8, 0.9, 0.8, 0.6, 1.0]`\n\n    *   Low sweetness, very high acidity, slight fruitiness.\n    *   Low savoryness, fully fermented.\n    *   Moderate cooking use, high salad use, very high preservation and sauce use.\n    *   Strong association with Western cuisine, good association with Eastern.\n    *   Highly common.\n\n**Explanation of Choices:**\n\n*   **Sweetness/Acidity:**  These are fundamental taste properties.\n*   **Fruitiness/Savoryness:**  Helps to differentiate between types of ingredients.\n*   **Fermented:** Distinguishes the core production of vinegar.\n*   **Cooking/Salad/Preservation/Sauce Use:** Indicates the typical applications.\n*   **Cuisine Association:**  Reflects cultural usage.\n*   **Commonality:** A general indicator of how frequently the ingredient is encountered.\n\n**Important Considerations:**\n\n*   **Subjectivity:**  These values are inherently subjective and depend on the specific interpretation. Different people might assign slightly different values.\n*   **Simplification:** This is a vastly simplified representation.  A real-world vector embedding (like those produced by Word2Vec or similar models) would have many more dimensions (often hundreds) and would be learned from a massive text corpus.\n*   **Context:** The ideal vector representation depends on the specific task. For example, if we were analyzing wine pairings, we might need dimensions related to tannins, body, and oakiness.\n*   **Normalization:** In real-world applications, vectors are often normalized (e.g., to unit length) to make comparisons more meaningful.\n\n**How to Use These Vectors:**\n\nYou can use these vectors to perform various operations:\n\n*   **Similarity Comparison:** Calculate the cosine similarity between the vectors to see how similar the ingredients are.\n*   **Clustering:** Group similar ingredients together based on their vector representations.\n*   **Ingredient Substitution:**  Find ingredients with similar vectors to suggest substitutes.\n*   **Recipe Analysis:**  Create a vector representation of an entire recipe by averaging the vectors of its ingredients.\n\nThis example demonstrates the basic idea of representing ingredients as vectors. In practice, you would typically use more sophisticated techniques and pre-trained models to generate more accurate and informative representations.\n‚ùå Error generating embedding: could not convert string to float: 'Okay'\nError: No valid embedding found for the user input.\nüç≤ Assistant (Similar Recipe Suggestion): Sorry, I couldn't find a matching recipe.\nüì¶ Assistant (Structured Recipe Info in JSON):\n{'error': '‚ö†Ô∏è Failed to parse structured recipe response.'}\n","output_type":"stream"}],"execution_count":null}]}